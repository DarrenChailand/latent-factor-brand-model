{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a6df0f",
   "metadata": {},
   "source": [
    "# Brand × Attribute Pipeline (End-to-End)\n",
    "\n",
    "This notebook runs the full pipeline:\n",
    "\n",
    "1. Build Brand × Attribute matrix from JSONL responses  \n",
    "2. Filter attributes with an LLM (OpenAI or Ollama)  \n",
    "3. Normalize/group attributes with Ollama  \n",
    "4. Compute PMI matrix  \n",
    "5. Run SVD on PMI  \n",
    "6. Compute brand–attribute importance scores + per-brand rankings\n",
    "\n",
    "> Assumes you added the notebook-friendly wrapper functions:\n",
    "- `run_build_matrix(...)` in `build_brand_attribute_matrix.py`\n",
    "- `run_filter_attributes(...)` in `filter_attributes_with_llm.py`\n",
    "- `run_normalize_attributes(...)` in the normalize script\n",
    "- `run_compute_pmi(...)` in `compute_pmi.py`\n",
    "- `run_svd(...)` in `run_svd.py`\n",
    "- `run_importance_from_outdir(...)` in `compute_importance_scores.py`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bd19da",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "\n",
    "Adjust paths here if your repo layout differs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d388e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- User-editable paths ---\n",
    "JSONL_INPUT = \"data/processed/responses/Appendix_A_responses.jsonl\"\n",
    "CONFIG_PATH = \"data/raw/demo_brand_prompt_config.json\"\n",
    "\n",
    "OUTDIR = \"data/processed/brand_attribute_matrix\"\n",
    "\n",
    "# Build\n",
    "STEM = \"raw\"\n",
    "PREFIX_ADJECTIVES = False\n",
    "\n",
    "# Filter\n",
    "FILTERED_CSV = f\"{OUTDIR}/filtered.csv\"\n",
    "DECISIONS_LOG = f\"{OUTDIR}/decisions-log.csv\"\n",
    "\n",
    "# Normalize\n",
    "NORMALIZED_CSV = f\"{OUTDIR}/filtered_normalized.csv\"\n",
    "\n",
    "# PMI\n",
    "PMI_CSV = f\"{OUTDIR}/pmi.csv\"\n",
    "\n",
    "# SVD\n",
    "K_SVD = 10\n",
    "\n",
    "# Importance (optionally truncate to top-k dims; None means use all saved dims)\n",
    "K_IMPORTANCE = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e63f44",
   "metadata": {},
   "source": [
    "## 1) Build Brand × Attribute matrix from JSONL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6caaa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_analysis.build_brand_attribute_matrix import run_build_matrix\n",
    "\n",
    "df_raw, raw_csv, raw_png = run_build_matrix(\n",
    "    input_jsonl=JSONL_INPUT,\n",
    "    outdir=OUTDIR,\n",
    "    config_path=CONFIG_PATH,\n",
    "    prefix_adjectives=PREFIX_ADJECTIVES,\n",
    "    stem=STEM,\n",
    ")\n",
    "\n",
    "print(\"Raw matrix:\", raw_csv)\n",
    "print(\"Raw heatmap:\", raw_png)\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d6afac",
   "metadata": {},
   "source": [
    "## 2) Filter attributes with an LLM\n",
    "\n",
    "This step uses whatever backend configuration you set inside `filter_attributes_with_llm.py`\n",
    "(e.g., `USE_OPENAI=True` / model name, or Ollama).  \n",
    "Make sure any required API keys are set in your environment if using OpenAI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_analysis.filter_attributes_with_llm import run_filter_attributes\n",
    "\n",
    "filtered_csv = run_filter_attributes(\n",
    "    input_csv=raw_csv,\n",
    "    output_csv=FILTERED_CSV,\n",
    "    decisions_log_csv=DECISIONS_LOG,\n",
    ")\n",
    "\n",
    "print(\"Filtered matrix:\", filtered_csv)\n",
    "pd.read_csv(filtered_csv, index_col=0).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806411f1",
   "metadata": {},
   "source": [
    "## 3) Normalize / group attributes (Ollama)\n",
    "\n",
    "This step groups synonyms and rewrites the matrix to canonical attribute columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_analysis.normalize_attributes_with_llm import run_normalize_attributes\n",
    "\n",
    "normalized_csv = run_normalize_attributes(\n",
    "    input_csv=filtered_csv,\n",
    "    outdir=OUTDIR,\n",
    "    chunk_size=60,\n",
    ")\n",
    "\n",
    "print(\"Normalized matrix:\", normalized_csv)\n",
    "pd.read_csv(normalized_csv, index_col=0).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eed968",
   "metadata": {},
   "source": [
    "## 4) Compute PMI matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c88ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_analysis.compute_pmi import run_compute_pmi\n",
    "\n",
    "PMI_df, pmi_path = run_compute_pmi(\n",
    "    input_csv=filtered_csv,   # or normalized_csv if you want PMI on normalized attributes\n",
    "    output_csv=PMI_CSV,\n",
    ")\n",
    "\n",
    "print(\"PMI matrix:\", pmi_path)\n",
    "PMI_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e72cb6",
   "metadata": {},
   "source": [
    "## 5) Run SVD on PMI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd13794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_analysis.run_svd import run_svd\n",
    "\n",
    "U_df, S_df, V_df = run_svd(\n",
    "    input_pmi_csv=pmi_path,\n",
    "    k=K_SVD,\n",
    "    outdir=OUTDIR,\n",
    ")\n",
    "\n",
    "display(S_df.head())\n",
    "U_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbee6a3",
   "metadata": {},
   "source": [
    "## 6) Compute Brand–Attribute importance scores + per-brand rankings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e94c77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_analysis.compute_importance_scores import run_importance_from_outdir\n",
    "\n",
    "importance_df, ranking_dict = run_importance_from_outdir(\n",
    "    input_outdir=OUTDIR,\n",
    "    k=K_IMPORTANCE,\n",
    ")\n",
    "\n",
    "importance_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51799a6f",
   "metadata": {},
   "source": [
    "## 7) Quick: show top attributes for a brand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2832f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = importance_df.index[0]\n",
    "top10 = ranking_dict[brand][\"top_attributes\"][:10]\n",
    "print(\"Brand:\", brand)\n",
    "print(\"Top 10 attributes:\", top10)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
